{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88905c75",
   "metadata": {},
   "source": [
    "**MODELLING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7264a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a01b095e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6418d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f29a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def call(self, inputs, verbose=False):\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "        def energy_step(inputs, states):\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "        def context_step(inputs, states):\n",
    "\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "              energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d7b10b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e22190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "lines = open('movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "convers = open('movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d63a1d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304714"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5281b9",
   "metadata": {},
   "source": [
    "**DATA PRE-PROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d13db114",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchn = []\n",
    "for conver in convers:\n",
    "    exchn.append(conver.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \" \").replace(\",\",\"\").split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87cda6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = {}\n",
    "for line in lines:\n",
    "    diag[line.split(' +++$+++ ')[0]] = line.split(' +++$+++ ')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dff44918",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(lines, convers, conver, line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423b3f9f",
   "metadata": {},
   "source": [
    "**CREATING LIST OF QUESTIONS AND ANSWERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea5a1d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b038bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for conver in exchn:\n",
    "    for i in range(len(conver) - 1):\n",
    "        questions.append(diag[conver[i]])\n",
    "        answers.append(diag[conver[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1af5fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(diag, exchn, conver, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f98e1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ques = []\n",
    "sorted_ans = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16c9f1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(questions)):\n",
    "    if len(questions[i]) < 13:\n",
    "        sorted_ques.append(questions[i])\n",
    "        sorted_ans.append(answers[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a7c414",
   "metadata": {},
   "source": [
    "**CLEANING OF DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66fafa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"i'm\", \"i am\", txt)\n",
    "    txt = re.sub(r\"he's\", \"he is\", txt)\n",
    "    txt = re.sub(r\"she's\", \"she is\", txt)\n",
    "    txt = re.sub(r\"that's\", \"that is\", txt)\n",
    "    txt = re.sub(r\"what's\", \"what is\", txt)\n",
    "    txt = re.sub(r\"where's\", \"where is\", txt)\n",
    "    txt = re.sub(r\"\\'ll\", \" will\", txt)\n",
    "    txt = re.sub(r\"\\'ve\", \" have\", txt)\n",
    "    txt = re.sub(r\"\\'re\", \" are\", txt)\n",
    "    txt = re.sub(r\"\\'d\", \" would\", txt)\n",
    "    txt = re.sub(r\"won't\", \"will not\", txt)\n",
    "    txt = re.sub(r\"can't\", \"can not\", txt)\n",
    "    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b4f6cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ques = []\n",
    "clean_ans = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddb91799",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in sorted_ques:\n",
    "    clean_ques.append(clean_text(line))\n",
    "        \n",
    "for line in sorted_ans:\n",
    "    clean_ans.append(clean_text(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f11e1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(answers, questions, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "706ba31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(clean_ans)):\n",
    "    clean_ans[i] = ' '.join(clean_ans[i].split()[:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "986482bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(sorted_ans, sorted_ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "221d1b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ans=clean_ans[:30000]\n",
    "clean_ques=clean_ques[:30000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86318b87",
   "metadata": {},
   "source": [
    "**CREATING VOCABULARY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2cdd7f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2count = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "054e1e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in clean_ques:\n",
    "    for word in line.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39350132",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in clean_ans:\n",
    "    for word in line.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "afcd43a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(word, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca3ca3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "191ecb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "word_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1059aaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, count in word2count.items():\n",
    "    if count >= thresh:\n",
    "        vocab[word] = word_num\n",
    "        word_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1797698",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(word2count, word, count, thresh)       \n",
    "del(word_num)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f64e60",
   "metadata": {},
   "source": [
    "**ADDING SOS AND EOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3dff9646",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(clean_ans)):\n",
    "    clean_ans[i] = '<SOS> ' + clean_ans[i] + ' <EOS>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "892ac98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
    "x = len(vocab)\n",
    "for token in tokens:\n",
    "    vocab[token] = x\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f41037fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab['cameron'] = vocab['<PAD>']\n",
    "vocab['<PAD>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9a2a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(token, tokens) \n",
    "del(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3ee44c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_vocab = {w:v for v, w in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b5b5966",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aad7f3",
   "metadata": {},
   "source": [
    "**CREATING ENCODER AND DECODER INPUTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7bf69fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inp = []\n",
    "for line in clean_ques:\n",
    "    lst = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            lst.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            lst.append(vocab[word])\n",
    "        \n",
    "    encoder_inp.append(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4793a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inp = []\n",
    "for line in clean_ans:\n",
    "    lst = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            lst.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            lst.append(vocab[word])        \n",
    "    decoder_inp.append(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7888a7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(clean_ans, clean_ques, line, lst, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "180c6f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05ffb07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inp = pad_sequences(encoder_inp, 13, padding='post', truncating='post')\n",
    "decoder_inp = pad_sequences(decoder_inp, 13, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c9a3bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_final_output = []\n",
    "for i in decoder_inp:\n",
    "    decoder_final_output.append(i[1:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd635d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_final_output = pad_sequences(decoder_final_output, 13, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccf3ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d689fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab)\n",
    "MAX_LEN = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1807435b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 13) (30000, 13) (30000, 13) 3027 3027 <PAD>\n"
     ]
    }
   ],
   "source": [
    "print(decoder_final_output.shape, decoder_inp.shape, encoder_inp.shape, len(vocab), len(inv_vocab), inv_vocab[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a61f78b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'they'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_vocab[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "35f0192e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13 3027\n",
      "(0, 13, 3027)\n"
     ]
    }
   ],
   "source": [
    "decoder_final_input = []\n",
    "print(len(decoder_final_input), MAX_LEN, VOCAB_SIZE)\n",
    "decoder_output_data = np.zeros((len(decoder_final_input), MAX_LEN, VOCAB_SIZE), dtype=\"float32\")\n",
    "print(decoder_output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "55c6ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "decoder_final_output = to_categorical(decoder_final_output, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "619bdb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 13, 3027)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_final_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67536d48",
   "metadata": {},
   "source": [
    "**GLOVE EMBEDDING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "efb13629",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "311020b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove Loded!\n"
     ]
    }
   ],
   "source": [
    "with open('glove.6B.50d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "\n",
    "print(\"Glove Loded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be91aa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimention = 50\n",
    "def embedding_matrix_creater(embedding_dimention, word_index):\n",
    "    embedding_matrix = np.zeros((len(word_index)+1, embedding_dimention))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "          # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "embedding_matrix = embedding_matrix_creater(50, word_index=vocab)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "47beb8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2ae2d8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3028, 50)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4e3ae789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf15343",
   "metadata": {},
   "source": [
    "**MODEL - LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8d17ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input, Bidirectional, Concatenate, Dropout, Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6f3b6d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = Embedding(VOCAB_SIZE+1, \n",
    "                  50, \n",
    "                  \n",
    "                  input_length=13,\n",
    "                  trainable=True)\n",
    "\n",
    "embed.build((None,))\n",
    "embed.set_weights([embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a36bfbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_inp = Input(shape=(13, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "497f47f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_embed = embed(enc_inp)\n",
    "enc_lstm = Bidirectional(LSTM(400, return_state=True, dropout=0.05, return_sequences = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a03033a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs, forward_h, forward_c, backward_h, backward_c = enc_lstm(enc_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8ca5df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "60c60c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fa2a2735",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_inp = Input(shape=(13, ))\n",
    "dec_embed = embed(dec_inp)\n",
    "dec_lstm = LSTM(400*2, return_state=True, return_sequences=True, dropout=0.05)\n",
    "output, _, _ = dec_lstm(dec_embed, initial_state=enc_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0a846ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_layer = AttentionLayer()\n",
    "attn_op, attn_state = attn_layer([encoder_outputs, output])\n",
    "decoder_concat_input = keras.layers.Concatenate(axis=-1)([output, attn_op])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bd277932",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_dense = Dense(VOCAB_SIZE, activation='softmax')\n",
    "final_output = dec_dense(decoder_concat_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "987d9ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([enc_inp, dec_inp], final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6fd5ce10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 13)]         0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 13)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 13, 50)       151400      ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  [(None, 13, 800),    1443200     ['embedding[0][0]']              \n",
      "                                 (None, 400),                                                     \n",
      "                                 (None, 400),                                                     \n",
      "                                 (None, 400),                                                     \n",
      "                                 (None, 400)]                                                     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 800)          0           ['bidirectional[0][1]',          \n",
      "                                                                  'bidirectional[0][3]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 800)          0           ['bidirectional[0][2]',          \n",
      "                                                                  'bidirectional[0][4]']          \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 13, 800),    2723200     ['embedding[1][0]',              \n",
      "                                 (None, 800),                     'concatenate[0][0]',            \n",
      "                                 (None, 800)]                     'concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 13, 1600)     0           ['lstm_1[0][0]',                 \n",
      "                                                                  'bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 13, 3027)     4846227     ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,164,027\n",
      "Trainable params: 9,164,027\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e3f5e1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8c75f2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6474756a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1063/1063 [==============================] - 966s 857ms/step - loss: 2.8929 - acc: 0.5144 - val_loss: 2.6787 - val_acc: 0.5331\n",
      "Epoch 2/40\n",
      "1063/1063 [==============================] - 856s 805ms/step - loss: 2.5481 - acc: 0.5422 - val_loss: 2.5716 - val_acc: 0.5427\n",
      "Epoch 3/40\n",
      "1063/1063 [==============================] - 850s 799ms/step - loss: 2.4017 - acc: 0.5513 - val_loss: 2.5416 - val_acc: 0.5476\n",
      "Epoch 4/40\n",
      "1063/1063 [==============================] - 913s 859ms/step - loss: 2.2631 - acc: 0.5585 - val_loss: 2.5573 - val_acc: 0.5491\n",
      "Epoch 5/40\n",
      "1063/1063 [==============================] - 926s 871ms/step - loss: 2.1059 - acc: 0.5679 - val_loss: 2.5920 - val_acc: 0.5481\n",
      "Epoch 6/40\n",
      "1063/1063 [==============================] - 1011s 951ms/step - loss: 1.9267 - acc: 0.5833 - val_loss: 2.6660 - val_acc: 0.5455\n",
      "Epoch 7/40\n",
      "1063/1063 [==============================] - 631s 594ms/step - loss: 1.7290 - acc: 0.6088 - val_loss: 2.7570 - val_acc: 0.5410\n",
      "Epoch 8/40\n",
      "1063/1063 [==============================] - 574s 540ms/step - loss: 1.5326 - acc: 0.6417 - val_loss: 2.8501 - val_acc: 0.5384\n",
      "Epoch 9/40\n",
      "1063/1063 [==============================] - 850s 800ms/step - loss: 1.3574 - acc: 0.6770 - val_loss: 2.9479 - val_acc: 0.5330\n",
      "Epoch 10/40\n",
      "1063/1063 [==============================] - 702s 660ms/step - loss: 1.1994 - acc: 0.7120 - val_loss: 3.0611 - val_acc: 0.5292\n",
      "Epoch 11/40\n",
      "1063/1063 [==============================] - 522s 491ms/step - loss: 1.0657 - acc: 0.7433 - val_loss: 3.1638 - val_acc: 0.5246\n",
      "Epoch 12/40\n",
      "1063/1063 [==============================] - 487s 458ms/step - loss: 0.9547 - acc: 0.7704 - val_loss: 3.2733 - val_acc: 0.5232\n",
      "Epoch 13/40\n",
      "1063/1063 [==============================] - 507s 477ms/step - loss: 0.8604 - acc: 0.7934 - val_loss: 3.3748 - val_acc: 0.5215\n",
      "Epoch 14/40\n",
      "1063/1063 [==============================] - 504s 474ms/step - loss: 0.7816 - acc: 0.8130 - val_loss: 3.4755 - val_acc: 0.5201\n",
      "Epoch 15/40\n",
      "1063/1063 [==============================] - 498s 469ms/step - loss: 0.7202 - acc: 0.8274 - val_loss: 3.5686 - val_acc: 0.5174\n",
      "Epoch 16/40\n",
      "1063/1063 [==============================] - 493s 463ms/step - loss: 0.6713 - acc: 0.8396 - val_loss: 3.6632 - val_acc: 0.5171\n",
      "Epoch 17/40\n",
      "1063/1063 [==============================] - 504s 474ms/step - loss: 0.6292 - acc: 0.8492 - val_loss: 3.7474 - val_acc: 0.5153\n",
      "Epoch 18/40\n",
      "1063/1063 [==============================] - 520s 489ms/step - loss: 0.5946 - acc: 0.8569 - val_loss: 3.8347 - val_acc: 0.5139\n",
      "Epoch 19/40\n",
      "1063/1063 [==============================] - 517s 487ms/step - loss: 0.5693 - acc: 0.8629 - val_loss: 3.9086 - val_acc: 0.5144\n",
      "Epoch 20/40\n",
      "1063/1063 [==============================] - 495s 466ms/step - loss: 0.5462 - acc: 0.8687 - val_loss: 3.9815 - val_acc: 0.5120\n",
      "Epoch 21/40\n",
      "1063/1063 [==============================] - 540s 508ms/step - loss: 0.5257 - acc: 0.8735 - val_loss: 4.0548 - val_acc: 0.5120\n",
      "Epoch 22/40\n",
      "1063/1063 [==============================] - 501s 471ms/step - loss: 0.5097 - acc: 0.8765 - val_loss: 4.1130 - val_acc: 0.5109\n",
      "Epoch 23/40\n",
      "1063/1063 [==============================] - 485s 456ms/step - loss: 0.5000 - acc: 0.8781 - val_loss: 4.1678 - val_acc: 0.5117\n",
      "Epoch 24/40\n",
      "1063/1063 [==============================] - 502s 473ms/step - loss: 0.4894 - acc: 0.8804 - val_loss: 4.2242 - val_acc: 0.5113\n",
      "Epoch 25/40\n",
      "1063/1063 [==============================] - 538s 506ms/step - loss: 0.4778 - acc: 0.8827 - val_loss: 4.2642 - val_acc: 0.5096\n",
      "Epoch 26/40\n",
      "1063/1063 [==============================] - 519s 488ms/step - loss: 0.4696 - acc: 0.8850 - val_loss: 4.3156 - val_acc: 0.5107\n",
      "Epoch 27/40\n",
      "1063/1063 [==============================] - 504s 474ms/step - loss: 0.4637 - acc: 0.8857 - val_loss: 4.3729 - val_acc: 0.5097\n",
      "Epoch 28/40\n",
      "1063/1063 [==============================] - 543s 511ms/step - loss: 0.4583 - acc: 0.8869 - val_loss: 4.4073 - val_acc: 0.5097\n",
      "Epoch 29/40\n",
      "1063/1063 [==============================] - 496s 467ms/step - loss: 0.4526 - acc: 0.8878 - val_loss: 4.4635 - val_acc: 0.5090\n",
      "Epoch 30/40\n",
      "1063/1063 [==============================] - 494s 464ms/step - loss: 0.4488 - acc: 0.8885 - val_loss: 4.4993 - val_acc: 0.5096\n",
      "Epoch 31/40\n",
      "1063/1063 [==============================] - 496s 467ms/step - loss: 0.4419 - acc: 0.8900 - val_loss: 4.5330 - val_acc: 0.5100\n",
      "Epoch 32/40\n",
      "1063/1063 [==============================] - 501s 471ms/step - loss: 0.4389 - acc: 0.8901 - val_loss: 4.5566 - val_acc: 0.5082\n",
      "Epoch 33/40\n",
      "1063/1063 [==============================] - 498s 469ms/step - loss: 0.4385 - acc: 0.8897 - val_loss: 4.5892 - val_acc: 0.5093\n",
      "Epoch 34/40\n",
      "1063/1063 [==============================] - 519s 488ms/step - loss: 0.4369 - acc: 0.8902 - val_loss: 4.6293 - val_acc: 0.5115\n",
      "Epoch 35/40\n",
      "1063/1063 [==============================] - 495s 466ms/step - loss: 0.4351 - acc: 0.8905 - val_loss: 4.6581 - val_acc: 0.5074\n",
      "Epoch 36/40\n",
      "1063/1063 [==============================] - 499s 470ms/step - loss: 0.4284 - acc: 0.8915 - val_loss: 4.6856 - val_acc: 0.5083\n",
      "Epoch 37/40\n",
      "1063/1063 [==============================] - 499s 470ms/step - loss: 0.4254 - acc: 0.8922 - val_loss: 4.7138 - val_acc: 0.5087\n",
      "Epoch 38/40\n",
      "1063/1063 [==============================] - 496s 467ms/step - loss: 0.4261 - acc: 0.8916 - val_loss: 4.7385 - val_acc: 0.5081\n",
      "Epoch 39/40\n",
      "1063/1063 [==============================] - 499s 469ms/step - loss: 0.4236 - acc: 0.8919 - val_loss: 4.7594 - val_acc: 0.5069\n",
      "Epoch 40/40\n",
      "1063/1063 [==============================] - 501s 471ms/step - loss: 0.4206 - acc: 0.8928 - val_loss: 4.7885 - val_acc: 0.5090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d39237b340>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_inp, decoder_inp], decoder_final_output, epochs=40, batch_size=24, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1222e90f",
   "metadata": {},
   "source": [
    "**INFERECE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "57708abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INFERECE\n",
    "model.save('chatbot.h5')\n",
    "model.save_weights('chatbot_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9da1f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention inference\n",
    "enc_model = tf.keras.models.Model(enc_inp, [encoder_outputs, enc_states])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d0d4c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = tf.keras.layers.Input(shape=( 400 * 2,))\n",
    "decoder_state_input_c = tf.keras.layers.Input(shape=( 400 * 2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0c24c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7ced7d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs, state_h, state_c = dec_lstm(dec_embed , initial_state=decoder_states_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "29311885",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "51a1c058",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_model = tf.keras.models.Model([dec_inp, decoder_states_inputs],\n",
    "                                      [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "390d603f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "#       start chatting ver. 1.0          #\n",
      "##########################################\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "print(\"##########################################\")\n",
    "print(\"#       start chatting ver. 1.0          #\")\n",
    "print(\"##########################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a2ea0de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you : hey\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "chatbot attention :  remember plans female any credit offense watch john john john john want john john \n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "prepro1 = input(\"you : \")\n",
    "prepro1 = clean_text(prepro1)\n",
    "prepro = [prepro1]\n",
    "\n",
    "txt = []\n",
    "for x in prepro:\n",
    "    lst = []\n",
    "    for y in x.split():\n",
    "        try:\n",
    "            lst.append(vocab[y])\n",
    "        except:\n",
    "            lst.append(vocab['<OUT>'])\n",
    "    txt.append(lst)\n",
    "txt = pad_sequences(txt, 13, padding='post')\n",
    "\n",
    "\n",
    "###\n",
    "enc_op, stat = enc_model.predict( txt )\n",
    "\n",
    "empty_target_seq = np.zeros( ( 1 , 1) )\n",
    "empty_target_seq[0, 0] = vocab['<SOS>']\n",
    "stop_condition = False\n",
    "decoded_translation = ''\n",
    "\n",
    "\n",
    "while not stop_condition :\n",
    "    \n",
    "    dec_inp = Input(shape=(13, 1, ))\n",
    "    enc_inp = Input(shape=(13, 1, ))\n",
    "\n",
    "    dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + stat )\n",
    "    ###\n",
    "    ###########################\n",
    "    #attn_op, attn_state = attn_layer([enc_op, dec_outputs])\n",
    "    #decoder_concat_input = Concatenate(axis=-1)([dec_outputs, attn_op])\n",
    "    #decoder_concat_input = dec_dense(decoder_concat_input)\n",
    "    ###########################\n",
    "\n",
    "    sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "\n",
    "    sampled_word = inv_vocab[sampled_word_index] + ' '\n",
    "\n",
    "    if sampled_word != '<EOS> ':\n",
    "        decoded_translation += sampled_word           \n",
    "\n",
    "\n",
    "    if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 13:\n",
    "        stop_condition = True\n",
    "\n",
    "    empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "    empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "    stat = [ h , c ] \n",
    "\n",
    "print(\"chatbot attention : \", decoded_translation )\n",
    "print(\"==============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c194a87",
   "metadata": {},
   "source": [
    "**CONCLUSION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6969b569",
   "metadata": {},
   "source": [
    "**I use seq2seq model for this project and  got the accuaracy as 0.89 which is quite good one.I tried to build attention mechanishm in this project but about 70% work very well the other part will be done as the future modifications.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db27e10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
